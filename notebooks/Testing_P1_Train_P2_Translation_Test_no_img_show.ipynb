{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "import model.create_dataset as create_dataset\n",
    "from model.utils import Params\n",
    "from model.model_fn import model_fn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'experiments/p1_training'\n",
    "#filename = 'data_for_model_resized_448*448/test/image_193.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(filename, image_size, channels):\n",
    "    # Read an image from a file\n",
    "    # Decode it into a dense vector\n",
    "    # Resize it to fixed shape\n",
    "    # Reshape it to 1 dimensional tensor\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=channels)\n",
    "    image_resized = tf.image.resize_images(image_decoded, [image_size, image_size])\n",
    "    features = tf.reshape(image_resized, [image_size*image_size*channels])\n",
    "    features_normalized = features / 255.0\n",
    "    return features_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dataset(filename, params):\n",
    "\n",
    "    # A tensor of only one filename\n",
    "    filename_tensor = tf.constant([filename])\n",
    "\n",
    "    # Load necessary params from config file\n",
    "    image_size = params.image_size\n",
    "    channels = 3 if params.rgb else 1\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(filename_tensor)\n",
    "    dataset = dataset.map(lambda filename: _parse_function(filename, image_size, channels))\n",
    "    dataset = dataset.batch(1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_embeddings(filename, estimator, params):\n",
    "        \n",
    "    # Compute embeddings for an image file\n",
    "    tf.logging.info(\"Predicting on \"+filename)\n",
    "\n",
    "    predictions = estimator.predict(lambda: _get_dataset(filename, params))\n",
    "\n",
    "    embeddings = np.zeros((1, params.embedding_size))\n",
    "    for i, p in enumerate(predictions):\n",
    "        embeddings[i] = p['embeddings']\n",
    "\n",
    "    tf.logging.info(\"Image embedding shape: {}\".format(embeddings.shape))\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating the model...\n",
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faaa57be080>, '_save_checkpoints_steps': None, '_tf_random_seed': 230, '_eval_distribute': None, '_model_dir': 'experiments/p1_training', '_experimental_distribute': None, '_evaluation_master': '', '_protocol': None, '_save_summary_steps': 50, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_save_checkpoints_secs': 600, '_train_distribute': None, '_task_id': 0, '_global_id_in_cluster': 0, '_num_ps_replicas': 0, '_device_fn': None, '_master': '', '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_is_chief': True, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Load the parameters from json file\n",
    "json_path = os.path.join(model_dir, 'params.json')\n",
    "assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "params = Params(json_path)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Define the model\n",
    "tf.logging.info(\"Creating the model...\")\n",
    "config = tf.estimator.RunConfig(tf_random_seed=230,\n",
    "                                model_dir=model_dir,\n",
    "                                save_summary_steps=params.save_summary_steps)\n",
    "estimator = tf.estimator.Estimator(model_fn, params=params, config=config)\n",
    "\n",
    "# Load landmark embeddings of TRANSLATED P1 from disk\n",
    "data = pd.read_csv(os.path.join(model_dir, \"landmarks/embeddings_new_p1.txt\"), sep=\"\\t\")\n",
    "data['embeddings'] = data['embeddings'].apply(lambda x : list(map(float, x.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total_image_count = 0\n",
    "for filename in glob.glob('person_05/Pose1/*.png'):\n",
    "    #print(filename)\n",
    "    img = load_img(filename, target_size=(224, 224))\n",
    "    # Get embeddings\n",
    "    embeddings = _get_embeddings(filename, estimator, params)\n",
    "    embeddings = np.round(embeddings, 6)\n",
    "    #print(embeddings)\n",
    "    # Compute image distance to all landmarks\n",
    "    data['dist'] = data['embeddings'].apply(lambda x : np.linalg.norm(embeddings - np.array(x)))\n",
    "    data['dist'] = np.round(data['dist'], 6) \n",
    "\n",
    "    # Get index of nearest neighbor\n",
    "    nnidx = data['dist'].idxmin()\n",
    "\n",
    "    # Output predicted class and distance\n",
    "    label = data['label'][nnidx]\n",
    "    dist = data['dist'][nnidx]\n",
    "    print(\"INFO:Image name is: {}\".format(filename))\n",
    "    print(\"INFO:Predicted class: {}\".format(label))\n",
    "    print(\"INFO:Distance: {}\".format(dist))\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    if label == ('Pose1'):\n",
    "        count+=1\n",
    "    total_image_count+=1\n",
    "print(\"Total count of correct predictions is {}\".format(count))\n",
    "print(\"Total image count is {}\".format(total_image_count))\n",
    "print(\"Accuracy is {}\".format((count/total_image_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "total_image_count = 0\n",
    "for filename in glob.glob('person_05/Pose2/*.png'):\n",
    "    #print(filename)\n",
    "    img = load_img(filename, target_size=(224, 224))\n",
    "    # Get embeddings\n",
    "    embeddings = _get_embeddings(filename, estimator, params)\n",
    "    embeddings = np.round(embeddings, 6)\n",
    "    #print(embeddings)\n",
    "    # Compute image distance to all landmarks\n",
    "    data['dist'] = data['embeddings'].apply(lambda x : np.linalg.norm(embeddings - np.array(x)))\n",
    "    data['dist'] = np.round(data['dist'], 6)\n",
    "\n",
    "    # Get index of nearest neighbor\n",
    "    nnidx = data['dist'].idxmin()\n",
    "\n",
    "    # Output predicted class and distance\n",
    "    label = data['label'][nnidx]\n",
    "    dist = data['dist'][nnidx]\n",
    "    print(\"INFO:Image name is: {}\".format(filename))\n",
    "    print(\"INFO:Predicted class: {}\".format(label))\n",
    "    print(\"INFO:Distance: {}\".format(dist))\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    if label == ('Pose2'):\n",
    "        count+=1\n",
    "    total_image_count+=1\n",
    "print(\"Total count of correct predictions is {}\".format(count))\n",
    "print(\"Total image count is {}\".format(total_image_count))\n",
    "print(\"Accuracy is {}\".format((count/total_image_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total_image_count = 0\n",
    "for filename in glob.glob('person_05/Pose3/*.png'):\n",
    "    #print(filename)\n",
    "    img = load_img(filename, target_size=(224, 224))\n",
    "    # Get embeddings\n",
    "    embeddings = _get_embeddings(filename, estimator, params)\n",
    "    embeddings = np.round(embeddings, 6)\n",
    "    #print(embeddings)\n",
    "    # Compute image distance to all landmarks\n",
    "    data['dist'] = data['embeddings'].apply(lambda x : np.linalg.norm(embeddings - np.array(x)))\n",
    "    data['dist'] = np.round(data['dist'], 6)\n",
    "\n",
    "    # Get index of nearest neighbor\n",
    "    nnidx = data['dist'].idxmin()\n",
    "\n",
    "    # Output predicted class and distance\n",
    "    label = data['label'][nnidx]\n",
    "    dist = data['dist'][nnidx]\n",
    "    print(\"INFO:Image name is: {}\".format(filename))\n",
    "    print(\"INFO:Predicted class: {}\".format(label))\n",
    "    print(\"INFO:Distance: {}\".format(dist))\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    if label == ('Pose3'):\n",
    "        count+=1\n",
    "    total_image_count+=1\n",
    "print(\"Total count of correct predictions is {}\".format(count))\n",
    "print(\"Total image count is {}\".format(total_image_count))\n",
    "print(\"Accuracy is {}\".format((count/total_image_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "total_image_count = 0\n",
    "for filename in glob.glob('person_05/Pose4/*.png'):\n",
    "    #print(filename)\n",
    "    img = load_img(filename, target_size=(224, 224))\n",
    "    # Get embeddings\n",
    "    embeddings = _get_embeddings(filename, estimator, params)\n",
    "    embeddings = np.round(embeddings, 6)\n",
    "    #print(embeddings)\n",
    "    # Compute image distance to all landmarks\n",
    "    data['dist'] = data['embeddings'].apply(lambda x : np.linalg.norm(embeddings - np.array(x)))\n",
    "    data['dist'] = np.round(data['dist'], 6)\n",
    "\n",
    "    # Get index of nearest neighbor\n",
    "    nnidx = data['dist'].idxmin()\n",
    "\n",
    "    # Output predicted class and distance\n",
    "    label = data['label'][nnidx]\n",
    "    dist = data['dist'][nnidx]\n",
    "    print(\"INFO:Image name is: {}\".format(filename))\n",
    "    print(\"INFO:Predicted class: {}\".format(label))\n",
    "    print(\"INFO:Distance: {}\".format(dist))\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    if label == ('Pose4'):\n",
    "        count+=1\n",
    "    total_image_count+=1\n",
    "print(\"Total count of correct predictions is {}\".format(count))\n",
    "print(\"Total image count is {}\".format(total_image_count))\n",
    "print(\"Accuracy is {}\".format((count/total_image_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "total_image_count = 0\n",
    "for filename in glob.glob('person_05/Pose5/*.png'):\n",
    "    #print(filename)\n",
    "    img = load_img(filename, target_size=(224, 224))\n",
    "    # Get embeddings\n",
    "    embeddings = _get_embeddings(filename, estimator, params)\n",
    "    embeddings = np.round(embeddings, 6)\n",
    "    #print(embeddings)\n",
    "    # Compute image distance to all landmarks\n",
    "    data['dist'] = data['embeddings'].apply(lambda x : np.linalg.norm(embeddings - np.array(x)))\n",
    "    data['dist'] = np.round(data['dist'], 6)\n",
    "\n",
    "    # Get index of nearest neighbor\n",
    "    nnidx = data['dist'].idxmin()\n",
    "\n",
    "    # Output predicted class and distance\n",
    "    label = data['label'][nnidx]\n",
    "    dist = data['dist'][nnidx]\n",
    "    print(\"INFO:Image name is: {}\".format(filename))\n",
    "    print(\"INFO:Predicted class: {}\".format(label))\n",
    "    print(\"INFO:Distance: {}\".format(dist))\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    if label == ('Pose5'):\n",
    "        count+=1\n",
    "    total_image_count+=1\n",
    "print(\"Total count of correct predictions is {}\".format(count))\n",
    "print(\"Total image count is {}\".format(total_image_count))\n",
    "print(\"Accuracy is {}\".format((count/total_image_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "total_image_count = 0\n",
    "for filename in glob.glob('person_05/Pose6/*.png'):\n",
    "    #print(filename)\n",
    "    img = load_img(filename, target_size=(224, 224))\n",
    "    # Get embeddings\n",
    "    embeddings = _get_embeddings(filename, estimator, params)\n",
    "    embeddings = np.round(embeddings, 6)\n",
    "    #print(embeddings)\n",
    "    # Compute image distance to all landmarks\n",
    "    data['dist'] = data['embeddings'].apply(lambda x : np.linalg.norm(embeddings - np.array(x)))\n",
    "    data['dist'] = np.round(data['dist'], 6)\n",
    "\n",
    "    # Get index of nearest neighbor\n",
    "    nnidx = data['dist'].idxmin()\n",
    "\n",
    "    # Output predicted class and distance\n",
    "    label = data['label'][nnidx]\n",
    "    dist = data['dist'][nnidx]\n",
    "    print(\"INFO:Image name is: {}\".format(filename))\n",
    "    print(\"INFO:Predicted class: {}\".format(label))\n",
    "    print(\"INFO:Distance: {}\".format(dist))\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    if label == ('Pose6'):\n",
    "        count+=1\n",
    "    total_image_count+=1\n",
    "print(\"Total count of correct predictions is {}\".format(count))\n",
    "print(\"Total image count is {}\".format(total_image_count))\n",
    "print(\"Accuracy is {}\".format((count/total_image_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
