{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/experiments/base_model/landmarks/embeddings.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_path, sep=\"\\t\") #sep=r\"\\,|\\t\", engine=\"python\",header=0\n",
    "#data.columns = [\"a\", \"b\", \"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'filename', 'embeddings'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E0','E1','E2','E3','E4','E5','E6','E7','E8','E9','E10','E11','E12','E13','E14','E15','E16','E17','E18','E19','E20','E21','E22','E23','E24','E25','E26','E27','E28','E29','E30','E31','E32','E33','E34','E35','E36','E37','E38','E39','E40','E41','E42','E43','E44','E45','E46','E47','E48','E49','E50','E51','E52','E53','E54','E55','E56','E57','E58','E59','E60','E61','E62','E63','E64',"
     ]
    }
   ],
   "source": [
    "for i in range(0,65):\n",
    "    print(\"'\"+\"E\"+ str(i)+\"'\"+\",\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['E0','E1','E2','E3','E4','E5','E6','E7','E8','E9','E10','E11','E12','E13','E14','E15','E16','E17','E18','E19','E20','E21','E22','E23','E24','E25','E26','E27','E28','E29','E30','E31','E32','E33','E34','E35','E36','E37','E38','E39','E40','E41','E42','E43','E44','E45','E46','E47','E48','E49','E50','E51','E52','E53','E54','E55','E56','E57','E58','E59','E60','E61','E62','E63']] = df['embeddings'].str.split(',',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pose1_df, Pose2_df, Pose3_df, Pose4_df, Pose5_df, Pose6_df\n",
    "\n",
    "Pose1, Pose2, Pose3, Pose4, Pose5, Pose6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pose1_df = df[(df.label == 'Pose1')]\n",
    "Pose1_df.to_pickle('dataframes/Pose1_df') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pose2_df = df[(df.label == 'Pose2')]\n",
    "Pose2_df.to_pickle('dataframes/Pose2_df') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pose3_df = df[(df.label == 'Pose3')]\n",
    "Pose3_df.to_pickle('dataframes/Pose3_df') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pose4_df = df[(df.label == 'Pose4')]\n",
    "Pose4_df.to_pickle('dataframes/Pose4_df') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pose5_df = df[(df.label == 'Pose5')]\n",
    "Pose5_df.to_pickle('dataframes/Pose5_df') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pose6_df = df[(df.label == 'Pose6')]\n",
    "Pose6_df.to_pickle('dataframes/Pose6_df') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pose7_df = df[(df.label == 'Pose7')]\n",
    "Pose7_df.to_pickle('dataframes/Pose7_df') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check t-sne on Person 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import model.create_dataset as create_dataset\n",
    "from model.utils import Params\n",
    "from model.model_fn import model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"experiments/base_model\"\n",
    "landmark_dir = \"Images/images_old/person_05_jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dataset(landmark_dir, params, class_dict_dir):\n",
    "\n",
    "    dataset = create_dataset.dataset(landmark_dir, params, class_dict_dir)\n",
    "    dataset = dataset.batch(params.batch_size)\n",
    "    dataset = dataset.prefetch(1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def _get_dataset_size(landmark_dir, image_type):\n",
    "\n",
    "\tsize = 0\n",
    "\tfor root, dirs, files in os.walk(landmark_dir):\n",
    "\t    files = [f for f in files if \".\"+image_type in f ]\n",
    "\t    size += len(files)\n",
    "\n",
    "\ttf.logging.info(\"Found {} {} landmarks in {}\".format(size, image_type, landmark_dir))\n",
    "\n",
    "\treturn size\n",
    "\n",
    "\n",
    "def _get_embeddings(landmark_dir, estimator, params, class_dict_dir, landmark_size):\n",
    "        \n",
    "    # Compute embeddings\n",
    "    tf.logging.info(\"Predicting on \"+landmark_dir)    \n",
    "\n",
    "    predictions = estimator.predict(lambda: _get_dataset(landmark_dir, params, class_dict_dir))\n",
    "\n",
    "    embeddings = np.zeros((landmark_size, params.embedding_size))\n",
    "    for i, p in enumerate(predictions):\n",
    "        embeddings[i] = p['embeddings']\n",
    "\n",
    "    tf.logging.info(\"Embeddings shape in \"+os.path.basename(landmark_dir)+\": {}\".format(embeddings.shape))\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load the parameters from json file\n",
    "    json_path = os.path.join(model_dir, 'params.json')\n",
    "    assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "    params = Params(json_path)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Define the model\n",
    "    tf.logging.info(\"Creating the model...\")\n",
    "    config = tf.estimator.RunConfig(tf_random_seed=230,\n",
    "                                    model_dir=model_dir,\n",
    "                                    save_summary_steps=params.save_summary_steps)\n",
    "    estimator = tf.estimator.Estimator(model_fn, params=params, config=config)\n",
    "\n",
    "    # Create a new folder to save embeddings\n",
    "    embeddings_dir = os.path.join(model_dir, \"landmarks\")\n",
    "    if not os.path.exists(embeddings_dir):\n",
    "        os.makedirs(embeddings_dir)\n",
    "\n",
    "    # Get the number of landmarks\n",
    "    landmark_size = _get_dataset_size(os.path.normpath(landmark_dir), params.image_type)\n",
    "\n",
    "    # Get embeddings and define tensorflow variables\n",
    "    embeddings = _get_embeddings(landmark_dir, estimator, params, embeddings_dir, landmark_size)\n",
    "    embeddings = np.round(embeddings, 6)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8210e-03,  1.0500e-04, -2.2956e-02, ..., -4.2740e-02,\n",
       "        -3.7427e-02, -3.2623e-02],\n",
       "       [ 2.2690e-03,  6.2100e-04, -2.2293e-02, ..., -4.3060e-02,\n",
       "        -3.7466e-02, -3.3096e-02],\n",
       "       [ 1.6970e-03, -1.6500e-04, -2.3087e-02, ..., -4.2439e-02,\n",
       "        -3.8011e-02, -3.2408e-02],\n",
       "       ...,\n",
       "       [ 1.6270e-03, -8.0000e-06, -2.3108e-02, ..., -4.2728e-02,\n",
       "        -3.7968e-02, -3.2378e-02],\n",
       "       [ 1.5980e-03,  2.3800e-04, -2.3256e-02, ..., -4.2621e-02,\n",
       "        -3.8015e-02, -3.2385e-02],\n",
       "       [ 1.3410e-03,  1.7100e-04, -2.3279e-02, ..., -4.2408e-02,\n",
       "        -3.7709e-02, -3.2543e-02]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "class IdentityMetadata():\n",
    "    def __init__(self, base, name, file):\n",
    "        # dataset base directory\n",
    "        self.base = base\n",
    "        # identity name\n",
    "        self.name = name\n",
    "        # image file name\n",
    "        self.file = file\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.image_path()\n",
    "\n",
    "    def image_path(self):\n",
    "        return os.path.join(self.base, self.name, self.file) \n",
    "s='jpg'\n",
    "a=\"jpeg\"    \n",
    "b=\"JPG\" \n",
    "c=\"png\" \n",
    "def load_metadata(path):\n",
    "    metadata = []\n",
    "    for i in os.listdir(path):\n",
    "        #print(i)\n",
    "        for f in os.listdir(os.path.join(path, i)):\n",
    "             if f.endswith(s) or f.endswith(a)  or f.endswith(b) or f.endswith(c):\n",
    "                metadata.append(IdentityMetadata(path, i, f))\n",
    "    return np.array(metadata)\n",
    "\n",
    "metadata = load_metadata(landmark_dir)\n",
    "#print(metadata)\n",
    "print(metadata.shape[0])\n",
    "\n",
    "targets = np.array([m.name for m in metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "X_embedded = TSNE(n_components=2).fit_transform(embeddings)\n",
    "#print(X_embedded)\n",
    "fig=plt.figure(figsize=(15,8))\n",
    "for i, t in enumerate(set(targets)):\n",
    "    idx = targets == t\n",
    "    plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=t)   \n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1));\n",
    "fig.savefig(\"cluster_p5.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check t-sne on Person 1, 2, 3 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"experiments/base_model\"\n",
    "landmark_dir = \"Images/p1_2_3_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load the parameters from json file\n",
    "    json_path = os.path.join(model_dir, 'params.json')\n",
    "    assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "    params = Params(json_path)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # Define the model\n",
    "    tf.logging.info(\"Creating the model...\")\n",
    "    config = tf.estimator.RunConfig(tf_random_seed=230,\n",
    "                                    model_dir=model_dir,\n",
    "                                    save_summary_steps=params.save_summary_steps)\n",
    "    estimator = tf.estimator.Estimator(model_fn, params=params, config=config)\n",
    "\n",
    "    # Create a new folder to save embeddings\n",
    "    embeddings_dir = os.path.join(model_dir, \"landmarks\")\n",
    "    if not os.path.exists(embeddings_dir):\n",
    "        os.makedirs(embeddings_dir)\n",
    "\n",
    "    # Get the number of landmarks\n",
    "    landmark_size = _get_dataset_size(os.path.normpath(landmark_dir), params.image_type)\n",
    "\n",
    "    # Get embeddings and define tensorflow variables\n",
    "    embeddings = _get_embeddings(landmark_dir, estimator, params, embeddings_dir, landmark_size)\n",
    "    embeddings = np.round(embeddings, 6)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2923\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "class IdentityMetadata():\n",
    "    def __init__(self, base, name, file):\n",
    "        # dataset base directory\n",
    "        self.base = base\n",
    "        # identity name\n",
    "        self.name = name\n",
    "        # image file name\n",
    "        self.file = file\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.image_path()\n",
    "\n",
    "    def image_path(self):\n",
    "        return os.path.join(self.base, self.name, self.file) \n",
    "s='jpg'\n",
    "a=\"jpeg\"    \n",
    "b=\"JPG\" \n",
    "c=\"png\" \n",
    "def load_metadata(path):\n",
    "    metadata = []\n",
    "    for i in os.listdir(path):\n",
    "        #print(i)\n",
    "        for f in os.listdir(os.path.join(path, i)):\n",
    "             if f.endswith(s) or f.endswith(a)  or f.endswith(b) or f.endswith(c):\n",
    "                metadata.append(IdentityMetadata(path, i, f))\n",
    "    return np.array(metadata)\n",
    "\n",
    "metadata = load_metadata(landmark_dir)\n",
    "#print(metadata)\n",
    "print(metadata.shape[0])\n",
    "\n",
    "targets = np.array([m.name for m in metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "X_embedded = TSNE(n_components=2).fit_transform(embeddings)\n",
    "#print(X_embedded)\n",
    "fig=plt.figure(figsize=(15,8))\n",
    "for i, t in enumerate(set(targets)):\n",
    "    idx = targets == t\n",
    "    plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], label=t)   \n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1));\n",
    "fig.savefig(\"cluster_p1_2_3_5.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
